{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Triangulation in Computer Vision\n",
    "\n",
    "Triangulation is a method used in computer vision to determine the 3D position of a point by using its 2D projections in multiple images taken from different perspectives. Itâ€™s a fundamental technique in stereo vision, structure from motion, and other 3D reconstruction tasks.\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "- **Camera Intrinsics**: Parameters that describe the camera's internal characteristics (e.g., focal length, principal point).\n",
    "- **Camera Extrinsics**: Parameters that describe the camera's position and orientation in the world (rotation and translation).\n",
    "- **Projection**: The process of mapping 3D points to 2D image points using camera intrinsics and extrinsics.\n",
    "- **Triangulation**: Given two or more 2D projections of the same 3D point from different camera views, triangulation estimates the 3D coordinates of that point.\n",
    "\n",
    "### The Triangulation Process\n",
    "\n",
    "- **Camera Matrices**: Compute the camera matrices for each camera view using the camera intrinsics and extrinsics.\n",
    "- **Projection Matrices**: Use the camera matrices to get the projection matrices.\n",
    "- **Linear System**: Set up a linear system of equations using the 2D image coordinates and the projection matrices.\n",
    "- **Solve**: Solve the linear system to find the 3D coordinates of the point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Triangulation with Two Cameras\n",
    "\n",
    "Assume we have two cameras capturing the same scene from different viewpoints, and we know the intrinsic and extrinsic parameters of both cameras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env OPEN3D_DISABLE_WEB_VISUALIZER=true\n",
    "\n",
    "from commons import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare two Landmarks in two Camera Views\n",
    "\n",
    "`uv_1` and `uv_2` are landmarks of the same wrist joint of the right hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two landmarks in the images\n",
    "uv1 = [267, 237]   # for camera 105322251225\n",
    "uv2 = [227, 322]   # for camera 117222250549"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the landmark on image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read image from two cameras\n",
    "rgb1 = read_rgb_image(\"../demo/recordings/20231022_193630/105322251225/color_000000.jpg\")\n",
    "rgb2 = read_rgb_image(\"../demo/recordings/20231022_193630/117222250549/color_000000.jpg\")\n",
    "\n",
    "# draw the landmarks\n",
    "vis1 = draw_landmarks_on_image(rgb1, [uv1], color=(0, 255, 0))\n",
    "vis2 = draw_landmarks_on_image(rgb2, [uv2], color=(0, 255, 0))\n",
    "\n",
    "display_images([vis1, vis2], [\"105322251225\", \"117222250549\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read K matrix of the camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read K matrix from calibration file\n",
    "K1 = read_K_matrix_from_json(\"../demo/calibration/intrinsics/105322251225_640x480.json\")\n",
    "print(f\"K1:\\n {K1}\")\n",
    "\n",
    "K2 = read_K_matrix_from_json(\"../demo/calibration/intrinsics/117222250549_640x480.json\")\n",
    "print(f\"K2:\\n {K2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Extrinsics of the camera\n",
    "\n",
    "- The loaded extrinsics are in the form of a 4x4 matrix.\n",
    "- Ecah extrinsic matrix `RT` is the camera pose from the camera to master_camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read extrinsics from calibration file\n",
    "RTs, master_camera = read_extrinsics_from_json(\"../demo/calibration/extrinsics/extrinsics_20231014/extrinsics.json\")\n",
    "\n",
    "RT1 = RTs[\"105322251225\"]\n",
    "RT1_inv = np.linalg.inv(RT1)\n",
    "\n",
    "print(f\"RT1:\\n {RT1}\")\n",
    "\n",
    "RT2 = RTs[\"117222250549\"]\n",
    "RT2_inv = np.linalg.inv(RT2)\n",
    "\n",
    "print(f\"RT2:\\n {RT2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the Camera Projection Matrix\n",
    "\n",
    "- The camera projection matrix is the product of the camera intrinsic matrix and the extrinsic matrix.\n",
    "- The projection matrix is a 3x4 matrix.\n",
    "\n",
    "$P = K \\cdot RT$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the projection matrices \n",
    "P1 = K1 @ RT1_inv[:3, :]\n",
    "\n",
    "print(f\"P1:\\n {P1}\")\n",
    "\n",
    "P2 = K2 @ RT2_inv[:3, :]\n",
    "\n",
    "print(f\"P2:\\n {P2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solve the Triangulation Problem\n",
    "\n",
    "- The function takes the projection matrices of two cameras and the 2D image coordinates of the point.\n",
    "- The matrix `A` is constructed by stacking the equations derived from the projection equations for each view.\n",
    "- Singular Value Decomposition (SVD): The 3D point is the right singular vector corresponding to the smallest singular value of `A`.\n",
    "- The solution is in homogeneous coordinates, so divide by the last element to get the 3D coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# triangulate two points\n",
    "def triangulate_point(uv1, uv2, P1, P2):\n",
    "    \"\"\" Triangulate a point from two views. \n",
    "    \n",
    "    Args:\n",
    "        uv1: 2D point in view 1, shape (2,)\n",
    "        uv2: 2D point in view 2, shape (2,)\n",
    "        P1: Projection matrix for view 1, shape (3, 4)\n",
    "        P2: Projection matrix for view 2, shape (3, 4)\n",
    "    Returns:\n",
    "        3D point\n",
    "    \"\"\"\n",
    "\n",
    "    # Construct the A matrix\n",
    "    A = np.zeros((4, 4))\n",
    "    A[0] = uv1[0] * P1[2] - P1[0]\n",
    "    A[1] = uv1[1] * P1[2] - P1[1]\n",
    "    A[2] = uv2[0] * P2[2] - P2[0]\n",
    "    A[3] = uv2[1] * P2[2] - P2[1]\n",
    "\n",
    "    # Perform SVD\n",
    "    _, _, V = np.linalg.svd(A)\n",
    "\n",
    "    # The last row of V gives the solution\n",
    "    X = V[-1]\n",
    "\n",
    "    # Convert from homogeneous to 3D coordinates\n",
    "    return X[:3] / X[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_3d = triangulate_point(uv1, uv2, P1, P2)\n",
    "\n",
    "print(f\"Triangulated 3D point:\\n {point_3d}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Triangulated 3D Point on image\n",
    "\n",
    "- First, we transform the 3D point from the master camera to the its own camera coordinate system.\n",
    "- Next, we project the camera space 3D point to the image plane for the pixel coordinate `(u, v)`.\n",
    "- Finally, we draw the `(u, v)` pixel on the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the 3D point to the camera frame\n",
    "point_3d_cam1 = apply_transformation([point_3d], RT1_inv)\n",
    "point_3d_cam2 = apply_transformation([point_3d], RT2_inv)\n",
    "\n",
    "# project the 3D point to the image\n",
    "uv1_proj = get_uv_from_xyz(point_3d_cam1[0], K1[0,0], K1[1,1], K1[0,2], K1[1,2])\n",
    "uv2_proj = get_uv_from_xyz(point_3d_cam2[0], K2[0,0], K2[1,1], K2[0,2], K2[1,2])\n",
    "\n",
    "print(f\"Projected uv_1: {uv1_proj}\")\n",
    "print(f\"Projected uv_2: {uv2_proj}\")\n",
    "\n",
    "# draw the projected points\n",
    "vis1_projected = draw_landmarks_on_image(rgb1, [uv1_proj], color=(255, 0, 0))\n",
    "vis2_projected = draw_landmarks_on_image(rgb2, [uv2_proj], color=(255, 0, 0))\n",
    "\n",
    "display_images(\n",
    "    images=[vis1, vis2, vis1_projected, vis2_projected], \n",
    "    names=[\"105322251225\", \"117222250549\", \"105322251225_proj\", \"117222250549_proj\"],\n",
    "    max_cols=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Triangulated 3D Point in 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read depth images\n",
    "depth1 = read_depth_image(\"../demo/recordings/20231022_193630/105322251225/depth_000000.png\")\n",
    "depth2 = read_depth_image(\"../demo/recordings/20231022_193630/117222250549/depth_000000.png\")\n",
    "\n",
    "# convert the depth images to meters\n",
    "depth1 = depth1.astype(np.float32) / 1000.0\n",
    "depth2 = depth2.astype(np.float32) / 1000.0\n",
    "\n",
    "# get the normalized colors\n",
    "colors1 = rgb1.reshape(-1, 3) / 255.0\n",
    "colors2 = rgb2.reshape(-1, 3) / 255.0\n",
    "\n",
    "# backproject the depth to 3D\n",
    "points1 = deproject_depth_image(depth1, K1, RT1)\n",
    "points2 = deproject_depth_image(depth2, K2, RT2)\n",
    "\n",
    "merged_points = np.vstack([points1, points2])\n",
    "merged_colors = np.vstack([colors1, colors2])\n",
    "\n",
    "# create the point cloud\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(merged_points)\n",
    "pcd.colors = o3d.utility.Vector3dVector(merged_colors)\n",
    "\n",
    "# create the sphere at the triangulated point\n",
    "sphere = o3d.geometry.TriangleMesh.create_sphere(radius=0.01)\n",
    "sphere.paint_uniform_color([1, 0, 0])   # red color\n",
    "sphere.translate(point_3d)\n",
    "\n",
    "# visualize the 3D points\n",
    "o3d.visualization.draw([pcd, sphere], point_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice\n",
    "\n",
    "Calculate the triangulated 3D points for below two cameras.\n",
    "\n",
    "- camera `108222250342`: `uv1 = (358, 321)` for the wrist joint of the left hand.\n",
    "- camera `046122250168`: `uv2 = (520, 257)` for the wrist joint of the left hand.\n",
    "\n",
    "Refer to the code [python_quizs_answer2.py](./python_quizs_answer2.py) for the answer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uv1 = (358, 321)    # for camera 108222250342\n",
    "uv2 = (520, 257)    # for camera 046122250168\n",
    "\n",
    "# load the intrinsics\n",
    "# write your code here\n",
    "\n",
    "# load the extrinsics and invert them\n",
    "# write your code here\n",
    "\n",
    "# calculate the projection matrices\n",
    "# write your code here\n",
    "\n",
    "# triangulate the points\n",
    "# write your code here\n",
    "\n",
    "# visualize the triangulated point in 3D\n",
    "# read the color & depth images\n",
    "# write your code here\n",
    "\n",
    "# convert the depth images to meters\n",
    "# write your code here\n",
    "\n",
    "# get the normalized colors\n",
    "# write your code here\n",
    "\n",
    "# backproject the depth to 3D\n",
    "# write your code here\n",
    "\n",
    "# merge the points and colors\n",
    "# write your code here\n",
    "\n",
    "# create the point cloud\n",
    "# write your code here\n",
    "\n",
    "# create the sphere at the triangulated point\n",
    "# write your code here\n",
    "\n",
    "# visualize the 3D points\n",
    "# write your code here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summer_camp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
